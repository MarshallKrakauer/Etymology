{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U -q segmentation-models\n",
    "# !pip install -q tensorflow==2.1\n",
    "# !pip install -q keras==2.3.1\n",
    "# !pip install -q tensorflow-estimator==2.1.\n",
    "\n",
    "# ## Imports libs\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
    "\n",
    "# from tensorflow import keras\n",
    "# import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from collections import Counter\n",
    "from keras.preprocessing import sequence\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_letter_mapping(all_words):\n",
    "    letter_li = []\n",
    "    \n",
    "    # Get unique letters in the data\n",
    "    for word in all_words:\n",
    "        for letter in word:\n",
    "            letter_li.append(letter)\n",
    "    \n",
    "    # order letters by most common\n",
    "    most_common = Counter(letter_li).most_common()\n",
    "    letter_li = []\n",
    "    for elem in most_common:\n",
    "        letter_li.append(elem[0])\n",
    "    \n",
    "    # Map each letter to an integer\n",
    "    letter_dict = {}\n",
    "    for idx, letter in enumerate(letter_li):\n",
    "        if letter_dict != '':\n",
    "            letter_dict[letter] = idx + 1\n",
    "        else:\n",
    "            letter_dict[letter] = 0\n",
    "    \n",
    "    return letter_dict\n",
    "\n",
    "def letter_to_number(word_li, letter_dict):\n",
    "    return_li = []\n",
    "    for letter in word_li:\n",
    "        return_li.append(letter_dict[letter])\n",
    "        \n",
    "    return return_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "lan_df = pd.read_csv('language_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lan_df = lan_df[lan_df['Group'] != 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "lan_df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dict = {}\n",
    "for idx, value in enumerate(lan_df.Group.unique()):\n",
    "    group_dict[value] = idx\n",
    "    \n",
    "lan_df['group_int'] = lan_df['Group'].apply(lambda x: group_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "lan_df['letter_li'] = lan_df['word'].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = create_letter_mapping(lan_df['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lan_df['letter_ints'] = lan_df['letter_li'].apply(lambda x: letter_to_number(x, map_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word                                 abs brake\n",
       "origin                                     deu\n",
       "full_name                               German\n",
       "Group                                 Germanic\n",
       "word_len                                     9\n",
       "group_int                                    0\n",
       "letter_li          [a, b, s,  , b, r, a, k, e]\n",
       "letter_ints    [3, 16, 8, 27, 16, 7, 3, 21, 1]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lan_df.iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = lan_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_arr = np.empty(SHAPE, dtype=list)\n",
    "origin_arr = np.empty(SHAPE, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(SHAPE):\n",
    "    word_arr[i] = lan_df.loc[i, 'letter_ints']\n",
    "    origin_arr[i] = lan_df.loc[i, 'group_int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad array so that all words have length of 25\n",
    "word_arr = sequence.pad_sequences(word_arr, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop random index for train test split\n",
    "random.seed(0)\n",
    "rng = np.arange(SHAPE)\n",
    "random.shuffle(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(SHAPE * 0.8)\n",
    "train_idx = rng[:train_len]\n",
    "test_idx = rng[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = word_arr[train_idx], origin_arr[train_idx]\n",
    "X_test, y_test = word_arr[test_idx], origin_arr[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(map_dict) + 1, 10),\n",
    "    tf.keras.layers.LSTM(10),\n",
    "    tf.keras.layers.Dense(len(group_dict), activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14935 samples, validate on 3734 samples\n",
      "Epoch 1/10\n",
      "14935/14935 [==============================] - 11s 750us/sample - loss: 0.5956 - acc: 0.8625 - val_loss: 0.4565 - val_acc: 0.8618\n",
      "Epoch 2/10\n",
      "14935/14935 [==============================] - 9s 584us/sample - loss: 0.4385 - acc: 0.8644 - val_loss: 0.4296 - val_acc: 0.86310.4378 - acc: 0.86\n",
      "Epoch 3/10\n",
      "14935/14935 [==============================] - 9s 573us/sample - loss: 0.4223 - acc: 0.8648 - val_loss: 0.4167 - val_acc: 0.8640\n",
      "Epoch 4/10\n",
      "14935/14935 [==============================] - 9s 590us/sample - loss: 0.4143 - acc: 0.8653 - val_loss: 0.4072 - val_acc: 0.8664\n",
      "Epoch 5/10\n",
      "14935/14935 [==============================] - 9s 599us/sample - loss: 0.4076 - acc: 0.8670 - val_loss: 0.4007 - val_acc: 0.8698\n",
      "Epoch 6/10\n",
      "14935/14935 [==============================] - 9s 586us/sample - loss: 0.4012 - acc: 0.8698 - val_loss: 0.3986 - val_acc: 0.8698\n",
      "Epoch 7/10\n",
      "14935/14935 [==============================] - 9s 596us/sample - loss: 0.3962 - acc: 0.8714 - val_loss: 0.3965 - val_acc: 0.8720\n",
      "Epoch 8/10\n",
      "14935/14935 [==============================] - 9s 593us/sample - loss: 0.3925 - acc: 0.8718 - val_loss: 0.3891 - val_acc: 0.8712\n",
      "Epoch 9/10\n",
      "14935/14935 [==============================] - 9s 604us/sample - loss: 0.3897 - acc: 0.8728 - val_loss: 0.3840 - val_acc: 0.8715\n",
      "Epoch 10/10\n",
      "14935/14935 [==============================] - 9s 607us/sample - loss: 0.3865 - acc: 0.8727 - val_loss: 0.4107 - val_acc: 0.8709\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  3, 21,  1],\n",
       "       [ 0,  0,  0, ...,  2, 19, 14],\n",
       "       [ 0,  0,  0, ..., 17,  1,  4],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  5,  2, 10],\n",
       "       [ 0,  0,  0, ...,  7,  6,  9],\n",
       "       [ 0,  0,  0, ..., 17, 11, 12]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>origin</th>\n",
       "      <th>full_name</th>\n",
       "      <th>Group</th>\n",
       "      <th>word_len</th>\n",
       "      <th>group_int</th>\n",
       "      <th>letter_li</th>\n",
       "      <th>letter_ints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abs brake</td>\n",
       "      <td>deu</td>\n",
       "      <td>German</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>[a, b, s,  , b, r, a, k, e]</td>\n",
       "      <td>[3, 16, 8, 27, 16, 7, 3, 21, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aivd</td>\n",
       "      <td>nld</td>\n",
       "      <td>Dutch;Flemish</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[a, i, v, d]</td>\n",
       "      <td>[3, 2, 19, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aachen</td>\n",
       "      <td>deu</td>\n",
       "      <td>German</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[a, a, c, h, e, n]</td>\n",
       "      <td>[3, 3, 10, 17, 1, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aarhus</td>\n",
       "      <td>dan</td>\n",
       "      <td>Danish</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[a, a, r, h, u, s]</td>\n",
       "      <td>[3, 3, 7, 17, 11, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ababil</td>\n",
       "      <td>ara</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, b, a, b, i, l]</td>\n",
       "      <td>[3, 16, 3, 16, 2, 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word origin      full_name     Group  word_len  group_int  \\\n",
       "0  abs brake    deu         German  Germanic         9          0   \n",
       "1       aivd    nld  Dutch;Flemish  Germanic         4          0   \n",
       "2     aachen    deu         German  Germanic         6          0   \n",
       "3     aarhus    dan         Danish  Germanic         6          0   \n",
       "4     ababil    ara         Arabic    Arabic         6          1   \n",
       "\n",
       "                     letter_li                      letter_ints  \n",
       "0  [a, b, s,  , b, r, a, k, e]  [3, 16, 8, 27, 16, 7, 3, 21, 1]  \n",
       "1                 [a, i, v, d]                   [3, 2, 19, 14]  \n",
       "2           [a, a, c, h, e, n]             [3, 3, 10, 17, 1, 4]  \n",
       "3           [a, a, r, h, u, s]             [3, 3, 7, 17, 11, 8]  \n",
       "4           [a, b, a, b, i, l]             [3, 16, 3, 16, 2, 9]  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>origin</th>\n",
       "      <th>full_name</th>\n",
       "      <th>Group</th>\n",
       "      <th>word_len</th>\n",
       "      <th>group_int</th>\n",
       "      <th>letter_li</th>\n",
       "      <th>letter_ints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9209</th>\n",
       "      <td>gasshohineri</td>\n",
       "      <td>jpn</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>[g, a, s, s, h, o, h, i, n, e, r, i]</td>\n",
       "      <td>[18, 3, 8, 8, 17, 6, 17, 2, 4, 1, 7, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9233</th>\n",
       "      <td>geisha</td>\n",
       "      <td>jpn</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[g, e, i, s, h, a]</td>\n",
       "      <td>[18, 1, 2, 8, 17, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>genkan</td>\n",
       "      <td>jpn</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[g, e, n, k, a, n]</td>\n",
       "      <td>[18, 1, 4, 21, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9289</th>\n",
       "      <td>genro</td>\n",
       "      <td>jpn</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>[g, e, n, r, o]</td>\n",
       "      <td>[18, 1, 4, 7, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9345</th>\n",
       "      <td>geta</td>\n",
       "      <td>jpn</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[g, e, t, a]</td>\n",
       "      <td>[18, 1, 5, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9360</th>\n",
       "      <td>gingko</td>\n",
       "      <td>jpn</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[g, i, n, g, k, o]</td>\n",
       "      <td>[18, 2, 4, 18, 21, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9441</th>\n",
       "      <td>gokkun</td>\n",
       "      <td>jpn</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[g, o, k, k, u, n]</td>\n",
       "      <td>[18, 6, 21, 21, 11, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9641</th>\n",
       "      <td>gunbai</td>\n",
       "      <td>jpn</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>[g, u, n, b, a, i]</td>\n",
       "      <td>[18, 11, 4, 16, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9669</th>\n",
       "      <td>gyotaku</td>\n",
       "      <td>jpn</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>[g, y, o, t, a, k, u]</td>\n",
       "      <td>[18, 15, 6, 5, 3, 21, 11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word origin full_name     Group  word_len  group_int  \\\n",
       "9209  gasshohineri    jpn  Japanese  Japanese        12          4   \n",
       "9233        geisha    jpn  Japanese  Japanese         6          4   \n",
       "9286        genkan    jpn  Japanese  Japanese         6          4   \n",
       "9289         genro    jpn  Japanese  Japanese         5          4   \n",
       "9345          geta    jpn  Japanese  Japanese         4          4   \n",
       "9360        gingko    jpn  Japanese  Japanese         6          4   \n",
       "9441        gokkun    jpn  Japanese  Japanese         6          4   \n",
       "9641        gunbai    jpn  Japanese  Japanese         6          4   \n",
       "9669       gyotaku    jpn  Japanese  Japanese         7          4   \n",
       "\n",
       "                                 letter_li  \\\n",
       "9209  [g, a, s, s, h, o, h, i, n, e, r, i]   \n",
       "9233                    [g, e, i, s, h, a]   \n",
       "9286                    [g, e, n, k, a, n]   \n",
       "9289                       [g, e, n, r, o]   \n",
       "9345                          [g, e, t, a]   \n",
       "9360                    [g, i, n, g, k, o]   \n",
       "9441                    [g, o, k, k, u, n]   \n",
       "9641                    [g, u, n, b, a, i]   \n",
       "9669                 [g, y, o, t, a, k, u]   \n",
       "\n",
       "                                  letter_ints  \n",
       "9209  [18, 3, 8, 8, 17, 6, 17, 2, 4, 1, 7, 2]  \n",
       "9233                     [18, 1, 2, 8, 17, 3]  \n",
       "9286                     [18, 1, 4, 21, 3, 4]  \n",
       "9289                         [18, 1, 4, 7, 6]  \n",
       "9345                            [18, 1, 5, 3]  \n",
       "9360                    [18, 2, 4, 18, 21, 6]  \n",
       "9441                   [18, 6, 21, 21, 11, 4]  \n",
       "9641                    [18, 11, 4, 16, 3, 2]  \n",
       "9669                [18, 15, 6, 5, 3, 21, 11]  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lan_df[(lan_df['Group'] == 'Japanese') & (lan_df['word'].str.startswith('g'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Germanic': 0, 'Arabic': 1, 'Latin': 2, 'Greek': 3, 'Japanese': 4}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 3, 64, 2, 11]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(elem * 100) for elem in model.predict(word_arr[9669:9669 + 1])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
